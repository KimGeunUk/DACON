{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2486,
     "status": "ok",
     "timestamp": 1733706289469,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "fpVYV14FKY_p",
    "outputId": "6018133c-9d72-4e1e-8206-3d61a5a9c5e4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7421,
     "status": "ok",
     "timestamp": 1733706296888,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "nMiTG7nqKV_L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733706296888,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "NfJj659DKV_Q"
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "# PATH = '/content/drive/MyDrive/KGW/dacon/k-water'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733706297590,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "pvj0a4c0KV_S"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"INPUT_WINDOW\"      : 4 * 24 * 7,   # 1 week, 60 * 24 * 7\n",
    "    \"BATCH_SIZE\"        : 128,\n",
    "    \"HIDDEN_DIM_LSTM\"   : 16,\n",
    "    \"NUM_LAYERS\"        : 1,\n",
    "    \"EPOCHS\"            : 1000,\n",
    "    \"LEARNING_RATE\"     : 1e-3,\n",
    "    \"PATIENCE\"          : 10,\n",
    "    \"RESAMPLE\"          : '15min',\n",
    "    \"DEVICE\"            : \"cpu\",\n",
    "    \"SAVE_PATH\"         : f\"{PATH}/weights/0203\"\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "\n",
    "CFG.DROPOUT = 0.0 if CFG.NUM_LAYERS < 2 else 0.2\n",
    "\n",
    "os.makedirs(CFG.SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = pd.read_csv(f\"{PATH}/data/train/TRAIN_A.csv\")\n",
    "df_B = pd.read_csv(f\"{PATH}/data/train/TRAIN_B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A['timestamp'] = pd.to_datetime(df_A['timestamp'], format=\"%y/%m/%d %H:%M\")\n",
    "df_A = df_A.set_index('timestamp')\n",
    "df_B['timestamp'] = pd.to_datetime(df_B['timestamp'], format=\"%y/%m/%d %H:%M\")\n",
    "df_B = df_B.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_resample = df_A.resample(f'{CFG.RESAMPLE}').mean()\n",
    "df_B_resample = df_A.resample(f'{CFG.RESAMPLE}').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A_resample = df_A_resample.reset_index('timestamp')\n",
    "df_B_resample = df_B_resample.reset_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733706297590,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "tDcor6B9KV_S"
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, stride: int = 1, inference: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: 입력 데이터프레임\n",
    "            stride: 윈도우 스트라이드\n",
    "            inference: 추론 모드 여부\n",
    "        \"\"\"\n",
    "        self.inference = inference\n",
    "        self.column_names = df.filter(regex='^P\\\\d+$').columns.tolist()\n",
    "        self.file_ids = df['file_id'].values if 'file_id' in df.columns else None\n",
    "\n",
    "        if inference:\n",
    "            self.values = df[self.column_names].values.astype(np.float32)\n",
    "            self._prepare_inference_data()\n",
    "        else:\n",
    "            self._prepare_training_data(df, stride)\n",
    "\n",
    "    def _normalize_columns(self, data: np.ndarray):\n",
    "        \"\"\"벡터화된 열 정규화\"\"\"\n",
    "        mins = data.min(axis=0, keepdims=True)\n",
    "        maxs = data.max(axis=0, keepdims=True)\n",
    "\n",
    "        # mins와 maxs가 같으면 전체를 0으로 반환\n",
    "        is_constant = (maxs == mins)\n",
    "        if np.any(is_constant):\n",
    "            normalized_data = np.zeros_like(data)\n",
    "            normalized_data[:, is_constant.squeeze()] = 0\n",
    "            return normalized_data\n",
    "\n",
    "        # 정규화 수행\n",
    "        return (data - mins) / (maxs - mins)\n",
    "\n",
    "    def _prepare_inference_data(self):\n",
    "        \"\"\"추론 데이터 준비 - 단일 시퀀스\"\"\"\n",
    "        self.normalized_values = self._normalize_columns(self.values)\n",
    "\n",
    "    def _prepare_training_data(self, df: pd.DataFrame, stride: int):\n",
    "        \"\"\"학습 데이터 준비 - 윈도우 단위\"\"\"\n",
    "        self.values = df[self.column_names].values.astype(np.float32)\n",
    "\n",
    "        # 시작 인덱스 계산 (stride 적용)\n",
    "        potential_starts = np.arange(0, len(df) - CFG.INPUT_WINDOW, stride)\n",
    "\n",
    "        # 각 윈도우의 마지막 다음 지점(window_size + 1)이 사고가 없는(0) 경우만 필터링\n",
    "        accident_labels = df['anomaly'].values\n",
    "        valid_starts = [\n",
    "            idx for idx in potential_starts\n",
    "            if idx + CFG.INPUT_WINDOW < len(df) and  # 범위 체크\n",
    "            accident_labels[idx + CFG.INPUT_WINDOW] == 0  # 윈도우 다음 지점 체크\n",
    "        ]\n",
    "        self.start_idx = np.array(valid_starts)\n",
    "\n",
    "        # 유효한 윈도우들만 추출하여 정규화\n",
    "        windows = np.array([\n",
    "            self.values[i:i + CFG.INPUT_WINDOW]\n",
    "            for i in self.start_idx\n",
    "        ])\n",
    "\n",
    "        # (윈도우 수, 윈도우 크기, 특성 수)로 한번에 정규화\n",
    "        self.input_data = np.stack([\n",
    "            self._normalize_columns(window) for window in windows\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.inference:\n",
    "            return len(self.column_names)\n",
    "        return len(self.start_idx) * len(self.column_names)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if self.inference:\n",
    "            col_idx = idx\n",
    "            col_name = self.column_names[col_idx]\n",
    "            col_data = self.normalized_values[:, col_idx]\n",
    "            file_id = self.file_ids[idx] if self.file_ids is not None else None\n",
    "            return {\n",
    "                \"column_name\": col_name,\n",
    "                \"input\": torch.from_numpy(col_data).unsqueeze(-1),  # (time_steps, 1)\n",
    "                \"file_id\": file_id\n",
    "            }\n",
    "\n",
    "        window_idx = idx // len(self.column_names)\n",
    "        col_idx = idx % len(self.column_names)\n",
    "\n",
    "        return {\n",
    "            \"column_name\": self.column_names[col_idx],\n",
    "            \"input\": torch.from_numpy(self.input_data[window_idx, :, col_idx]).unsqueeze(-1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2330,
     "status": "ok",
     "timestamp": 1733702193713,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "PZ_BhQxCKV_T"
   },
   "outputs": [],
   "source": [
    "train_dataset_A = TimeSeriesDataset(df_A[:int(len(df_A)*0.8)], stride=60)\n",
    "train_dataset_B = TimeSeriesDataset(df_B[:int(len(df_A)*0.8)], stride=60)\n",
    "train_dataset_A_B = torch.utils.data.ConcatDataset([train_dataset_A, train_dataset_B])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_A_B,\n",
    "                                            batch_size=CFG.BATCH_SIZE,\n",
    "                                            shuffle=True)\n",
    "\n",
    "valid_dataset_A = TimeSeriesDataset(df_A[int(len(df_A)*0.8):], stride=60)\n",
    "valid_dataset_B = TimeSeriesDataset(df_B[int(len(df_A)*0.8):], stride=60)\n",
    "valid_dataset_A_B = torch.utils.data.ConcatDataset([valid_dataset_A, valid_dataset_B])\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset_A_B,\n",
    "                                            batch_size=CFG.BATCH_SIZE,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733706297591,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "N8_ox-EHKV_V"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, hidden = self.lstm(x)\n",
    "        return outputs, hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, encoder_hidden):\n",
    "        outputs, hidden = self.lstm(x, encoder_hidden)\n",
    "        output = self.linear(outputs.squeeze(1))\n",
    "        return output, hidden\n",
    "\n",
    "class LSTMEncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, output_size):\n",
    "        super(LSTMEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.encoder = Encoder(input_size, hidden_size, num_layers, dropout)\n",
    "        self.decoder = Decoder(input_size, hidden_size, num_layers, dropout, input_size)\n",
    "\n",
    "    def forward(self, inputs, teacher_forcing_ratio=0.0):\n",
    "        batch_size, seq_len = inputs.size(0), inputs.size(1)\n",
    "        _, hidden = self.encoder(inputs)\n",
    "        last_hidden = hidden[0][-1]\n",
    "\n",
    "        outputs = torch.zeros(batch_size, seq_len, self.output_size, dtype=torch.float32).to(inputs.device)\n",
    "\n",
    "        decoder_input = inputs[:, -1, :].unsqueeze(1)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            output, hidden = self.decoder(decoder_input, hidden)\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                decoder_input = inputs[:, t, :].unsqueeze(1)\n",
    "            else:\n",
    "                decoder_input = output.unsqueeze(1)\n",
    "\n",
    "        reconstructed_hidden = hidden[0][-1]\n",
    "\n",
    "        return last_hidden, reconstructed_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2856,
     "status": "ok",
     "timestamp": 1733706300444,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "0L-nmZW-L_yv",
    "outputId": "80cd6406-cc8e-42d4-e783-d61e5db5fe24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 16]) torch.Size([128, 16])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMEncoderDecoder(1, CFG.HIDDEN_DIM_LSTM, CFG.NUM_LAYERS, CFG.DROPOUT, 1).to(CFG.DEVICE)\n",
    "x = model(torch.randn(128, 672, 1).to(CFG.DEVICE), 1.0)\n",
    "print(x[0].shape, x[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733706300444,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "F5zLaH1PKV_W"
   },
   "outputs": [],
   "source": [
    "def run(model, train_loader, optimizer, scheduler, criterion, n_epochs, device):\n",
    "    best_model = {\n",
    "        \"loss\": float('inf'),\n",
    "        \"state\": None,\n",
    "        \"epoch\": 0,\n",
    "        \"epochs_no_improve\": 0\n",
    "    }\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs}\", unit=\"batch\") as t:\n",
    "            for batch in t:\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                original_hidden, reconstructed_hidden = model(inputs, 0.0) # [ Batch_size, HIDDEN_DIM_LSTM ]\n",
    "\n",
    "                loss = criterion(reconstructed_hidden, original_hidden)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss = train_loss + loss.item()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(valid_loader, desc=f\"Epoch {epoch + 1}/{n_epochs}\", unit=\"batch\") as t:\n",
    "                for batch in t:\n",
    "                    inputs = batch[\"input\"].to(device)\n",
    "                    original_hidden, reconstructed_hidden = model(inputs, 0.0) # [ Batch_size, HIDDEN_DIM_LSTM ]\n",
    "\n",
    "                    loss = criterion(reconstructed_hidden, original_hidden)\n",
    "\n",
    "                    valid_loss = valid_loss + loss.item()\n",
    "                    t.set_postfix(loss=loss.item())\n",
    "                    \n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "        valid_losses.append(avg_valid_loss)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(avg_valid_loss)\n",
    "            lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Average Train Loss: {avg_train_loss:e}, Average Valid Loss: {avg_valid_loss:e}, Learning Rate: {lr:e}\", end=\" \")\n",
    "        \n",
    "        if avg_valid_loss < best_model[\"loss\"]:\n",
    "            best_model[\"state\"] = model.state_dict()\n",
    "            best_model[\"loss\"] = avg_valid_loss\n",
    "            best_model[\"epoch\"] = epoch + 1\n",
    "            best_model[\"epoch_no_improve\"] = 0\n",
    "            torch.save(best_model[\"state\"], f'{CFG.SAVE_PATH}/mse{avg_valid_loss:e}.pt')\n",
    "            print(\"Best Model Update & Saved !\")\n",
    "        else:\n",
    "            best_model[\"epoch_no_improve\"] += 1\n",
    "            print(\"\")\n",
    "\n",
    "        if best_model[\"epoch_no_improve\"] >= CFG.PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}. Validation loss did not improve for {CFG.PATIENCE} consecutive epochs.\")\n",
    "            break\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            clear_output()\n",
    "            \n",
    "    return train_losses, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2456,
     "status": "ok",
     "timestamp": 1733706302898,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "dRXlnVrmJjfE"
   },
   "outputs": [],
   "source": [
    "MODEL = LSTMEncoderDecoder(1, CFG.HIDDEN_DIM_LSTM, CFG.NUM_LAYERS, CFG.DROPOUT, 1).to(CFG.DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(MODEL.parameters(), lr=CFG.LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, threshold=1e-16, min_lr=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIyqAaGvKV_X",
    "outputId": "85ae0e22-038b-4139-c092-ff90d28a6771"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000:  14%|█▍        | 23/163 [01:52<11:23,  4.88s/batch, loss=0.00361]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_losses, valid_losses, best_model \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 24\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(model, train_loader, optimizer, scheduler, criterion, n_epochs, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(reconstructed_hidden, original_hidden)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m+\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\venv\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\venv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses, best_model = run(\n",
    "    MODEL,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    criterion=criterion,\n",
    "    n_epochs=CFG.EPOCHS,\n",
    "    device=CFG.DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1733706307380,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "G8fmUiTXKV_Y",
    "outputId": "89a31ca8-4547-4fa9-bcf5-85c815cae5f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFER_MODEL = LSTMEncoderDecoder(1, CFG.HIDDEN_DIM_LSTM, CFG.NUM_LAYERS, CFG.DROPOUT, 1).to(CFG.DEVICE)\n",
    "INFER_MODEL.load_state_dict(torch.load(f'{PATH}/weights/H128_L1_mse0.0000000002804242.pt', weights_only=True, map_location=CFG.DEVICE)) # best_model[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2333085,
     "status": "ok",
     "timestamp": 1733704535601,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "cNsQ0Hw-KV_Y",
    "outputId": "d9b08bb9-b43c-4848-d305-4fdc27f4fd35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [12:07<00:00,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold calculated and saved: 2.182152458729547e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_and_save_threshold(MODEL, train_loader, percentile=98):\n",
    "    MODEL.eval()\n",
    "    train_errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(train_loader):\n",
    "            inputs = batch[\"input\"].to(CFG.DEVICE)\n",
    "            original_hidden, reconstructed_hidden = MODEL(inputs, 0.0)\n",
    "            mse_errors = torch.mean((original_hidden - reconstructed_hidden) ** 2, dim=1).cpu().numpy()\n",
    "            train_errors.extend(mse_errors)\n",
    "\n",
    "    threshold = np.percentile(train_errors, percentile)\n",
    "\n",
    "    print(f\"Threshold calculated and saved: {threshold}\")\n",
    "    return threshold\n",
    "\n",
    "THRESHOLD = calculate_and_save_threshold(INFER_MODEL, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733706314530,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "At9X7xqBKV_Y"
   },
   "outputs": [],
   "source": [
    "def inference_test_files(MODEL, batch, device='cuda'):\n",
    "    MODEL.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = batch[\"input\"].to(device)\n",
    "        original_hidden, reconstructed_hidden = MODEL(inputs)\n",
    "        reconstruction_loss = torch.mean((original_hidden - reconstructed_hidden) ** 2, dim=1).cpu().numpy()\n",
    "    return reconstruction_loss\n",
    "\n",
    "def detect_anomaly(MODEL, test_directory):\n",
    "    test_files = [f for f in os.listdir(test_directory) if f.startswith(\"TEST\") and f.endswith(\".csv\")]\n",
    "    test_datasets = []\n",
    "    all_test_data = []\n",
    "\n",
    "    for filename in tqdm(test_files, desc='Processing test files'):\n",
    "        test_file = os.path.join(test_directory, filename)\n",
    "        df = pd.read_csv(test_file)\n",
    "        df['file_id'] = filename.replace('.csv', '')\n",
    "        individual_df = df[['timestamp', 'file_id'] + df.filter(like='P').columns.tolist()]\n",
    "        individual_dataset = TimeSeriesDataset(individual_df, inference=True)\n",
    "        test_datasets.append(individual_dataset)\n",
    "\n",
    "        all_test_data.append(df)\n",
    "\n",
    "    combined_dataset = torch.utils.data.ConcatDataset(test_datasets)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(combined_dataset,  batch_size=128,  shuffle=False)\n",
    "\n",
    "    reconstruction_errors = []\n",
    "    for batch in tqdm(test_loader):\n",
    "        reconstruction_loss = inference_test_files(MODEL, batch, CFG.DEVICE)\n",
    "\n",
    "        for i in range(len(reconstruction_loss)):\n",
    "            reconstruction_errors.append({\n",
    "                \"ID\": batch[\"file_id\"][i],\n",
    "                \"column_name\": batch[\"column_name\"][i],\n",
    "                \"reconstruction_error\": reconstruction_loss[i]\n",
    "            })\n",
    "\n",
    "    errors_df = pd.DataFrame(reconstruction_errors)\n",
    "\n",
    "    flag_columns = []\n",
    "    for column in sorted(errors_df['column_name'].unique()):\n",
    "        flag_column = f'{column}_flag'\n",
    "        errors_df[flag_column] = (errors_df.loc[errors_df['column_name'] == column, 'reconstruction_error'] > THRESHOLD).astype(int)\n",
    "        flag_columns.append(flag_column)\n",
    "\n",
    "    errors_df_pivot = errors_df.pivot_table(index='ID',\n",
    "                                          columns='column_name',\n",
    "                                          values=flag_columns,\n",
    "                                          aggfunc='first')\n",
    "    errors_df_pivot.columns = [f'{col[1]}' for col in errors_df_pivot.columns]\n",
    "    errors_df_flat = errors_df_pivot.reset_index()\n",
    "\n",
    "    errors_df_flat['flag_list'] = errors_df_flat.loc[:, 'P1':'P' + str(len(flag_columns))].apply(lambda x: x.tolist(), axis=1).apply(lambda x: [int(i) for i in x])\n",
    "    return combined_dataset, errors_df, errors_df_flat[[\"ID\", \"flag_list\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3z8RhFtq22Vt",
    "outputId": "0d808453-fff1-4010-d508-5f9aacf88c61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test files: 100%|██████████| 2920/2920 [08:32<00:00,  5.69it/s]\n",
      "100%|██████████| 183/183 [20:07<00:00,  6.60s/it]\n"
     ]
    }
   ],
   "source": [
    "C_dataset, C_error_df, C_list = detect_anomaly(INFER_MODEL, test_directory=f\"{PATH}/data/test/C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_ITSqeVa2tPV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test files: 100%|██████████| 2738/2738 [05:42<00:00,  8.01it/s]\n",
      "100%|██████████| 129/129 [12:26<00:00,  5.79s/it]\n"
     ]
    }
   ],
   "source": [
    "D_dataset, D_error_df, D_list = detect_anomaly(INFER_MODEL, test_directory=f\"{PATH}/data/test/D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "cZONgvpX24rR"
   },
   "outputs": [],
   "source": [
    "C_D_list = pd.concat([C_list, D_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "K-n98hlOKV_Z"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(f\"{PATH}/data/sample_submission.csv\")\n",
    "\n",
    "flag_mapping = C_D_list.set_index(\"ID\")[\"flag_list\"]\n",
    "sample_submission[\"flag_list\"] = sample_submission[\"ID\"].map(flag_mapping).fillna(sample_submission[\"flag_list\"])\n",
    "\n",
    "sample_submission.to_csv(f\"{PATH}/results/LSTM_ED_H128_L1_mse0.0000000002804242.pt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB2_91P8fN6y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
