{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3167,
     "status": "ok",
     "timestamp": 1734056539160,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "fpVYV14FKY_p",
    "outputId": "1e68c62a-4ab5-483e-bfcd-2495dde0285c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nMiTG7nqKV_L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from types import SimpleNamespace\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NfJj659DKV_Q"
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "# PATH = '/content/drive/MyDrive/KGW/dacon/k-water'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"INPUT_WINDOW\"      : 4 * 24 * 7,\n",
    "    \"BATCH_SIZE\"        : 128,\n",
    "    \"HIDDEN_DIM_LSTM\"   : 1024,\n",
    "    \"NUM_LAYERS\"        : 1,\n",
    "    \"EPOCHS\"            : 1000,\n",
    "    \"LEARNING_RATE\"     : 1e-3,\n",
    "    \"DEVICE\"            : \"cpu\",\n",
    "    \"PATIENCE\"          : 10,\n",
    "    \"RESAMPLE\"          : '15min',\n",
    "    \"SAVE_PATH\"         : f\"{PATH}/weights/1214\"\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "\n",
    "CFG.DROPOUT = 0.0 if CFG.NUM_LAYERS < 2 else 0.2\n",
    "\n",
    "os.makedirs(CFG.SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LPbQt8T8KV_R"
   },
   "outputs": [],
   "source": [
    "df_A = pd.read_csv(f\"{PATH}/data/train/TRAIN_A.csv\")\n",
    "df_B = pd.read_csv(f\"{PATH}/data/train/TRAIN_B.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r6puXKD_iXaW"
   },
   "outputs": [],
   "source": [
    "df_A['timestamp'] = pd.to_datetime(df_A['timestamp'], format=\"%y/%m/%d %H:%M\")\n",
    "df_A = df_A.set_index('timestamp')\n",
    "df_B['timestamp'] = pd.to_datetime(df_B['timestamp'], format=\"%y/%m/%d %H:%M\")\n",
    "df_B = df_B.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tRzS3MzkiRin"
   },
   "outputs": [],
   "source": [
    "df_A_resample = df_A.resample(f'{CFG.RESAMPLE}').mean()\n",
    "df_B_resample = df_A.resample(f'{CFG.RESAMPLE}').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6bTT2V_5i3NU"
   },
   "outputs": [],
   "source": [
    "df_A_resample = df_A_resample.reset_index('timestamp')\n",
    "df_B_resample = df_B_resample.reset_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tDcor6B9KV_S"
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, stride: int = 1, inference: bool = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: 입력 데이터프레임\n",
    "            stride: 윈도우 스트라이드\n",
    "            inference: 추론 모드 여부\n",
    "        \"\"\"\n",
    "        self.inference = inference\n",
    "        self.column_names = df.filter(regex='^P\\\\d+$').columns.tolist()\n",
    "        self.file_ids = df['file_id'].values if 'file_id' in df.columns else None\n",
    "\n",
    "        if inference:\n",
    "            self.values = df[self.column_names].values.astype(np.float32)\n",
    "            self._prepare_inference_data()\n",
    "        else:\n",
    "            self._prepare_training_data(df, stride)\n",
    "\n",
    "    def _normalize_columns(self, data: np.ndarray):\n",
    "        \"\"\"벡터화된 열 정규화\"\"\"\n",
    "        mins = data.min(axis=0, keepdims=True)\n",
    "        maxs = data.max(axis=0, keepdims=True)\n",
    "\n",
    "        # mins와 maxs가 같으면 전체를 0으로 반환\n",
    "        is_constant = (maxs == mins)\n",
    "        if np.any(is_constant):\n",
    "            normalized_data = np.zeros_like(data)\n",
    "            normalized_data[:, is_constant.squeeze()] = 0\n",
    "            return normalized_data\n",
    "\n",
    "        # 정규화 수행\n",
    "        return (data - mins) / (maxs - mins)\n",
    "\n",
    "    def _prepare_inference_data(self):\n",
    "        \"\"\"추론 데이터 준비 - 단일 시퀀스\"\"\"\n",
    "        self.normalized_values = self._normalize_columns(self.values)\n",
    "\n",
    "    def _prepare_training_data(self, df: pd.DataFrame, stride: int):\n",
    "        \"\"\"학습 데이터 준비 - 윈도우 단위\"\"\"\n",
    "        self.values = df[self.column_names].values.astype(np.float32)\n",
    "\n",
    "        # 시작 인덱스 계산 (stride 적용)\n",
    "        potential_starts = np.arange(0, len(df) - CFG.INPUT_WINDOW, stride)\n",
    "\n",
    "        # 각 윈도우의 마지막 다음 지점(window_size + 1)이 사고가 없는(0) 경우만 필터링\n",
    "        accident_labels = df['anomaly'].values\n",
    "        valid_starts = [\n",
    "            idx for idx in potential_starts\n",
    "            if idx + CFG.INPUT_WINDOW < len(df) and  # 범위 체크\n",
    "            accident_labels[idx + CFG.INPUT_WINDOW] == 0  # 윈도우 다음 지점 체크\n",
    "        ]\n",
    "        self.start_idx = np.array(valid_starts)\n",
    "\n",
    "        # 유효한 윈도우들만 추출하여 정규화\n",
    "        windows = np.array([\n",
    "            self.values[i:i + CFG.INPUT_WINDOW]\n",
    "            for i in self.start_idx\n",
    "        ])\n",
    "\n",
    "        # (윈도우 수, 윈도우 크기, 특성 수)로 한번에 정규화\n",
    "        self.input_data = np.stack([\n",
    "            self._normalize_columns(window) for window in windows\n",
    "        ])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.inference:\n",
    "            return len(self.column_names)\n",
    "        return len(self.start_idx) * len(self.column_names)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if self.inference:\n",
    "            col_idx = idx\n",
    "            col_name = self.column_names[col_idx]\n",
    "            col_data = self.normalized_values[:, col_idx]\n",
    "            file_id = self.file_ids[idx] if self.file_ids is not None else None\n",
    "            return {\n",
    "                \"column_name\": col_name,\n",
    "                \"input\": torch.from_numpy(col_data).unsqueeze(-1),  # (time_steps, 1)\n",
    "                \"file_id\": file_id\n",
    "            }\n",
    "\n",
    "        window_idx = idx // len(self.column_names)\n",
    "        col_idx = idx % len(self.column_names)\n",
    "\n",
    "        return {\n",
    "            \"column_name\": self.column_names[col_idx],\n",
    "            \"input\": torch.from_numpy(self.input_data[window_idx, :, col_idx]).unsqueeze(-1)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PZ_BhQxCKV_T"
   },
   "outputs": [],
   "source": [
    "train_dataset_A = TimeSeriesDataset(df_A_resample[:int(len(df_A_resample)*0.75)], stride=30)\n",
    "train_dataset_B = TimeSeriesDataset(df_B_resample[:int(len(df_B_resample)*0.75)], stride=30)\n",
    "train_dataset_A_B = torch.utils.data.ConcatDataset([train_dataset_A, train_dataset_B])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset_A_B, batch_size=CFG.BATCH_SIZE, shuffle=True)\n",
    "\n",
    "valid_dataset_A = TimeSeriesDataset(df_A_resample[int(len(df_A_resample)*0.75):], stride=30)\n",
    "valid_dataset_B = TimeSeriesDataset(df_B_resample[int(len(df_B_resample)*0.75):], stride=30)\n",
    "valid_dataset_A_B = torch.utils.data.ConcatDataset([valid_dataset_A, valid_dataset_B])\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset_A_B, batch_size=CFG.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "N8_ox-EHKV_V"
   },
   "outputs": [],
   "source": [
    "class LSTM_AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_AE, self).__init__()\n",
    "\n",
    "        # LSTM feature extractor\n",
    "        self.lstm_feature = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=CFG.HIDDEN_DIM_LSTM,\n",
    "            num_layers=CFG.NUM_LAYERS,\n",
    "            batch_first=True,\n",
    "            dropout=CFG.DROPOUT if CFG.NUM_LAYERS > 1 else 0\n",
    "        )\n",
    "\n",
    "        # Encoder modules\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(CFG.HIDDEN_DIM_LSTM, CFG.HIDDEN_DIM_LSTM//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(CFG.HIDDEN_DIM_LSTM//4, CFG.HIDDEN_DIM_LSTM//8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder modules\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(CFG.HIDDEN_DIM_LSTM//8, CFG.HIDDEN_DIM_LSTM//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(CFG.HIDDEN_DIM_LSTM//4, CFG.HIDDEN_DIM_LSTM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm_feature(x)\n",
    "        last_hidden = hidden[-1]  # (batch, hidden_dim)\n",
    "\n",
    "        # AE\n",
    "        latent_z = self.encoder(last_hidden)\n",
    "        reconstructed_hidden = self.decoder(latent_z)\n",
    "\n",
    "        return last_hidden, reconstructed_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "F5zLaH1PKV_W"
   },
   "outputs": [],
   "source": [
    "def run(model, train_loader, valid_loader, optimizer, scheduler, criterion, n_epochs, device):\n",
    "    best_model = {\n",
    "        \"loss\": float('inf'),\n",
    "        \"state\": None,\n",
    "        \"epoch\": 0,\n",
    "        \"epochs_no_improve\": 0\n",
    "    }\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs}\", unit=\"batch\") as t:\n",
    "            for batch in t:\n",
    "                inputs = batch[\"input\"].to(device)\n",
    "                original_hidden, reconstructed_hidden = model(inputs) # [ Batch_size, HIDDEN_DIM_LSTM ]\n",
    "\n",
    "                loss = criterion(reconstructed_hidden, original_hidden)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss = train_loss + loss.item()\n",
    "                t.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with tqdm(valid_loader, desc=f\"Epoch {epoch + 1}/{n_epochs}\", unit=\"batch\") as t:\n",
    "                for batch in t:\n",
    "                    inputs = batch[\"input\"].to(device)\n",
    "                    original_hidden, reconstructed_hidden = model(inputs) # [ Batch_size, HIDDEN_DIM_LSTM ]\n",
    "\n",
    "                    loss = criterion(reconstructed_hidden, original_hidden)\n",
    "\n",
    "                    valid_loss = valid_loss + loss.item()\n",
    "                    t.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "        valid_losses.append(avg_valid_loss)\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step(avg_valid_loss)\n",
    "            lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Average Train Loss: {avg_train_loss:e}, Average Valid Loss: {avg_valid_loss:e}, Learning Rate: {lr:e}\", end=\" \")\n",
    "\n",
    "        if avg_valid_loss < best_model[\"loss\"]:\n",
    "            best_model[\"state\"] = model.state_dict()\n",
    "            best_model[\"loss\"] = avg_valid_loss\n",
    "            best_model[\"epoch\"] = epoch + 1\n",
    "            best_model[\"epoch_no_improve\"] = 0\n",
    "            torch.save(best_model[\"state\"], f'{CFG.SAVE_PATH}/mse{avg_valid_loss:e}.pt')\n",
    "            print(\"Best Model Update & Saved !\")\n",
    "        else:\n",
    "            best_model[\"epoch_no_improve\"] += 1\n",
    "            print(\"\")\n",
    "\n",
    "        if best_model[\"epoch_no_improve\"] >= CFG.PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}. Validation loss did not improve for {CFG.PATIENCE} consecutive epochs.\")\n",
    "            break\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            clear_output()\n",
    "\n",
    "    return train_losses, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SB3T055Cgv8e"
   },
   "outputs": [],
   "source": [
    "MODEL = LSTM_AE().to(CFG.DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(MODEL.parameters(), lr=CFG.LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, threshold=1e-16, min_lr=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PGVcCy6fx8vF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL.load_state_dict(torch.load(f'{CFG.SAVE_PATH}/mse4.136487e-09.pt', weights_only=True, map_location=CFG.DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIyqAaGvKV_X",
    "outputId": "eecc34b1-c4b5-48ff-db0c-327072b4c2cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000: 100%|██████████| 22/22 [42:55<00:00, 117.08s/batch, loss=5.91e-12]\n",
      "Epoch 22/1000: 100%|██████████| 1/1 [00:03<00:00,  3.16s/batch, loss=6.06e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000, Average Train Loss: 8.618550e-12, Average Valid Loss: 6.055994e-12, Learning Rate: 1.000000e-04 Best Model Update & Saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000: 100%|██████████| 22/22 [42:58<00:00, 117.21s/batch, loss=1.34e-11]\n",
      "Epoch 23/1000: 100%|██████████| 1/1 [00:03<00:00,  3.25s/batch, loss=5.86e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000, Average Train Loss: 8.472536e-12, Average Valid Loss: 5.855559e-12, Learning Rate: 1.000000e-04 Best Model Update & Saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000: 100%|██████████| 22/22 [42:43<00:00, 116.52s/batch, loss=6.9e-12] \n",
      "Epoch 24/1000: 100%|██████████| 1/1 [00:03<00:00,  3.34s/batch, loss=5.62e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000, Average Train Loss: 8.155029e-12, Average Valid Loss: 5.619593e-12, Learning Rate: 1.000000e-04 Best Model Update & Saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000: 100%|██████████| 22/22 [43:22<00:00, 118.29s/batch, loss=7.02e-12]\n",
      "Epoch 25/1000: 100%|██████████| 1/1 [00:03<00:00,  3.44s/batch, loss=5.49e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000, Average Train Loss: 8.137751e-12, Average Valid Loss: 5.489143e-12, Learning Rate: 1.000000e-04 Best Model Update & Saved !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000: 100%|██████████| 22/22 [43:14<00:00, 117.92s/batch, loss=7.89e-12]\n",
      "Epoch 26/1000: 100%|██████████| 1/1 [00:03<00:00,  3.45s/batch, loss=5.62e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000, Average Train Loss: 8.197529e-12, Average Valid Loss: 5.623356e-12, Learning Rate: 1.000000e-04 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000: 100%|██████████| 22/22 [44:45<00:00, 122.05s/batch, loss=4.13e-12]\n",
      "Epoch 27/1000: 100%|██████████| 1/1 [00:03<00:00,  3.49s/batch, loss=5.54e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000, Average Train Loss: 8.062329e-12, Average Valid Loss: 5.543807e-12, Learning Rate: 1.000000e-04 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000:   0%|          | 0/22 [00:00<?, ?batch/s]"
     ]
    }
   ],
   "source": [
    "train_losses, best_model = run(\n",
    "    MODEL,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    criterion=criterion,\n",
    "    n_epochs=CFG.EPOCHS,\n",
    "    device=CFG.DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G8fmUiTXKV_Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFER_MODEL = LSTM_AE().to(CFG.DEVICE)\n",
    "INFER_MODEL.load_state_dict(torch.load(f'{CFG.SAVE_PATH}/mse5.489143e-12.pt', weights_only=True, map_location=CFG.DEVICE)) # best_model[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372425,
     "status": "ok",
     "timestamp": 1734048338155,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "cNsQ0Hw-KV_Y",
    "outputId": "8bcf91b5-ec2e-4f4c-93fd-88b22005ba4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:48<00:00,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold calculated and saved: 5.736964375779863e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_and_save_threshold(MODEL, train_loader, percentile=98):\n",
    "    MODEL.eval()\n",
    "    train_errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(train_loader):\n",
    "            inputs = batch[\"input\"].to(CFG.DEVICE)\n",
    "            original_hidden, reconstructed_hidden = MODEL(inputs)\n",
    "            mse_errors = torch.mean((original_hidden - reconstructed_hidden) ** 2, dim=1).cpu().numpy()\n",
    "            train_errors.extend(mse_errors)\n",
    "\n",
    "    threshold = np.percentile(train_errors, percentile)\n",
    "\n",
    "    print(f\"Threshold calculated and saved: {threshold}\")\n",
    "    return threshold\n",
    "\n",
    "THRESHOLD = calculate_and_save_threshold(INFER_MODEL, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_test_files(MODEL, batch, device='cuda'):\n",
    "    MODEL.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = batch[\"input\"].to(device)\n",
    "        original_hidden, reconstructed_hidden = MODEL(inputs)\n",
    "        reconstruction_loss = torch.mean((original_hidden - reconstructed_hidden) ** 2, dim=1).cpu().numpy()\n",
    "    return reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test files:   0%|          | 0/2920 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test files: 100%|██████████| 2920/2920 [01:51<00:00, 26.23it/s]\n",
      "Processing test files: 100%|██████████| 2738/2738 [01:43<00:00, 26.53it/s]\n"
     ]
    }
   ],
   "source": [
    "def save_dataset(where):\n",
    "    if where == \"C\":\n",
    "        test_directory=f\"{PATH}/data/test/C\"\n",
    "    else:\n",
    "        test_directory=f\"{PATH}/data/test/D\"\n",
    "        \n",
    "    test_files = [f for f in os.listdir(test_directory) if f.startswith(\"TEST\") and f.endswith(\".csv\")]\n",
    "    test_datasets = []\n",
    "\n",
    "    for filename in tqdm(test_files, desc='Processing test files'):\n",
    "        test_file = os.path.join(test_directory, filename)\n",
    "        \n",
    "        df = pd.read_csv(test_file)\n",
    "        df['file_id'] = filename.replace('.csv', '')\n",
    "        \n",
    "        individual_df = df[['timestamp', 'file_id'] + df.filter(like='P').columns.tolist()]\n",
    "        individual_df = individual_df.set_index(pd.date_range('2024-01-01', '2024-01-07 23:59:59', freq='1min'))\n",
    "        file_id = individual_df['file_id'].values[0]\n",
    "        individual_df = individual_df.drop(columns=['timestamp', 'file_id'])\n",
    "        individual_df = individual_df.resample(f'{CFG.RESAMPLE}').mean()\n",
    "        individual_df['file_id'] = file_id\n",
    "        \n",
    "        individual_dataset = TimeSeriesDataset(individual_df, inference=True)\n",
    "        test_datasets.append(individual_dataset)\n",
    "\n",
    "    combined_dataset = torch.utils.data.ConcatDataset(test_datasets)\n",
    "    \n",
    "    with open(f'{PATH}/data/{where}_dataset_{CFG.RESAMPLE}.pkl', 'wb') as f:\n",
    "        pickle.dump(combined_dataset, f)\n",
    "        \n",
    "save_dataset(where=\"C\")\n",
    "save_dataset(where=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "At9X7xqBKV_Y"
   },
   "outputs": [],
   "source": [
    "def detect_anomaly(MODEL, where):\n",
    "    with open(f'./data/{where}_dataset_{CFG.RESAMPLE}.pkl', 'rb') as f:\n",
    "        combined_dataset = pickle.load(f)    \n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader( combined_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    reconstruction_errors = []\n",
    "    for batch in tqdm(test_loader):\n",
    "        reconstruction_loss = inference_test_files(MODEL, batch, CFG.DEVICE)\n",
    "\n",
    "        for i in range(len(reconstruction_loss)):\n",
    "            reconstruction_errors.append({\n",
    "                \"ID\": batch[\"file_id\"][i],\n",
    "                \"column_name\": batch[\"column_name\"][i],\n",
    "                \"reconstruction_error\": reconstruction_loss[i]\n",
    "            })\n",
    "\n",
    "    errors_df = pd.DataFrame(reconstruction_errors)\n",
    "\n",
    "    flag_columns = []\n",
    "    for column in sorted(errors_df['column_name'].unique()):\n",
    "        flag_column = f'{column}_flag'\n",
    "        errors_df[flag_column] = (errors_df.loc[errors_df['column_name'] == column, 'reconstruction_error'] > THRESHOLD).astype(int)\n",
    "        flag_columns.append(flag_column)\n",
    "\n",
    "    errors_df_pivot = errors_df.pivot_table(index='ID', columns='column_name', values=flag_columns, aggfunc='first')\n",
    "    errors_df_pivot.columns = [f'{col[1]}' for col in errors_df_pivot.columns]\n",
    "    errors_df_flat = errors_df_pivot.reset_index()\n",
    "\n",
    "    errors_df_flat['flag_list'] = errors_df_flat.loc[:, 'P1':'P' + str(len(flag_columns))].apply(lambda x: x.tolist(), axis=1).apply(lambda x: [int(i) for i in x])\n",
    "    return errors_df_flat[[\"ID\", \"flag_list\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 500808,
     "status": "ok",
     "timestamp": 1734048838959,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "3z8RhFtq22Vt",
    "outputId": "bc0b4898-3110-4a9e-9d89-fa48d0b77b83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/92 [00:29<22:03, 14.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m C_list \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_anomaly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINFER_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m, in \u001b[0;36mdetect_anomaly\u001b[1;34m(MODEL, where)\u001b[0m\n\u001b[0;32m      7\u001b[0m reconstruction_errors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader):\n\u001b[1;32m----> 9\u001b[0m     reconstruction_loss \u001b[38;5;241m=\u001b[39m \u001b[43minference_test_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reconstruction_loss)):\n\u001b[0;32m     12\u001b[0m         reconstruction_errors\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     13\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m][i],\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m\"\u001b[39m][i],\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreconstruction_error\u001b[39m\u001b[38;5;124m\"\u001b[39m: reconstruction_loss[i]\n\u001b[0;32m     16\u001b[0m         })\n",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m, in \u001b[0;36minference_test_files\u001b[1;34m(MODEL, batch, device)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      4\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 5\u001b[0m     original_hidden, reconstructed_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mMODEL\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     reconstruction_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((original_hidden \u001b[38;5;241m-\u001b[39m reconstructed_hidden) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reconstruction_loss\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\.kgw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\.kgw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mLSTM_AE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 30\u001b[0m     _, (hidden, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     last_hidden \u001b[38;5;241m=\u001b[39m hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# (batch, hidden_dim)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# AE\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\.kgw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\.kgw\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\kgw\\Desktop\\kgw\\projects\\.kgw\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C_list = detect_anomaly(INFER_MODEL, where=\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439907,
     "status": "ok",
     "timestamp": 1734049278860,
     "user": {
      "displayName": "김근욱",
      "userId": "15218882410485618642"
     },
     "user_tz": -540
    },
    "id": "_ITSqeVa2tPV",
    "outputId": "a2e937d6-224c-428e-9ff5-e30ba5f925fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [10:46<00:00,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "D_list = detect_anomaly(INFER_MODEL, where=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cZONgvpX24rR"
   },
   "outputs": [],
   "source": [
    "C_D_list = pd.concat([C_list, D_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "K-n98hlOKV_Z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>flag_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_C_0000</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_C_0001</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_C_0002</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_C_0003</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_C_0004</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                 flag_list\n",
       "0  TEST_C_0000  [0, 0, 0, 0, 0, 0, 0, 0]\n",
       "1  TEST_C_0001  [1, 1, 1, 1, 1, 1, 1, 0]\n",
       "2  TEST_C_0002  [0, 0, 0, 0, 0, 0, 0, 0]\n",
       "3  TEST_C_0003  [0, 0, 0, 0, 0, 0, 0, 0]\n",
       "4  TEST_C_0004  [0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(f\"{PATH}/data/sample_submission.csv\")\n",
    "# 매핑된 값으로 업데이트하되, 매핑되지 않은 경우 기존 값 유지\n",
    "flag_mapping = C_D_list.set_index(\"ID\")[\"flag_list\"]\n",
    "sample_submission[\"flag_list\"] = sample_submission[\"ID\"].map(flag_mapping).fillna(sample_submission[\"flag_list\"])\n",
    "\n",
    "sample_submission.to_csv(f\"{PATH}/results/LSTM_ED_IW{CFG.INPUT_WINDOW}_H{CFG.HIDDEN_DIM_LSTM}_L{CFG.NUM_LAYERS}_22.csv\", index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjZNV5_HKV_Z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".kgw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
