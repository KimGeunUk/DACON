{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 gpkg 파일은 분리되어 있는것 같다. 합쳐주기 위해서 folder path를 받아오자 \n",
    "old_f_path = f'/workspace/daegu/data/external_open/대구 빅데이터 마트 데이터/7. 안전/2. 보행노인사고 다발지역'\n",
    "jaywalk_f_path = f'/workspace/daegu/data/external_open/대구 빅데이터 마트 데이터/7. 안전/5. 보행자무단횡단사고 다발지역'\n",
    "ice_f_path = f'/workspace/daegu/data/external_open/대구 빅데이터 마트 데이터/7. 안전/8. 결빙사고 다발지역'\n",
    "truck_f_path = f'/workspace/daegu/data/external_open/대구 빅데이터 마트 데이터/7. 안전/9. 화물차사고 다발지역'\n",
    "walker_f_path = f'/workspace/daegu/data/external_open/대구 빅데이터 마트 데이터/7. 안전/11. 보행자사고 다발지역'\n",
    "\n",
    "# 각 folder path 내에서 gpkg 확장자 파일의 이름을 추출해서 list로 만들자 \n",
    "old_fnames = glob.glob(f'{old_f_path}/*.gpkg')\n",
    "jaywalk_fnames = glob.glob(f'{jaywalk_f_path}/*.gpkg')\n",
    "ice_fnames = glob.glob(f'{ice_f_path}/*.gpkg')\n",
    "truck_fnames = glob.glob(f'{truck_f_path}/*.gpkg')\n",
    "walker_fnames = glob.glob(f'{walker_f_path}/*.gpkg')\n",
    "\n",
    "# fnames 변수의 list를 만들자 \n",
    "fname_list = [old_fnames, jaywalk_fnames, ice_fnames, truck_fnames, walker_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "def gpd_merge(file_names):\n",
    "\n",
    "    gdfs = []\n",
    "\n",
    "    # Load each GeoPackage file in the list\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            gdf = gpd.read_file(file_name, encoding='cp949')\n",
    "            \n",
    "            gdf = gdf.dropna()\n",
    "\n",
    "            gdfs.append(gdf)\n",
    "\n",
    "            print(f\"Loaded GeoPackage file: {file_name}\")\n",
    "            print(f\"Number of rows after removing missing values: {len(gdf)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {file_name}: {e}\")\n",
    "\n",
    "    # 좌표계 변환 : EPSG:5179 -> EPSG:4326\n",
    "    merged_gdf = pd.concat(gdfs, axis=0)\n",
    "    merged_gdf.geometry = merged_gdf.geometry.to_crs('EPSG:4326')\n",
    "\n",
    "    # geometry 열로부터 위도, 경도 열을 추가함 (multipoligon의 center?)\n",
    "    merged_gdf['위도'] = merged_gdf['geometry'].apply(lambda geom: geom.centroid.y if geom.geom_type == 'Point' else geom.centroid.y)\n",
    "    merged_gdf['경도'] = merged_gdf['geometry'].apply(lambda geom: geom.centroid.x if geom.geom_type == 'Point' else geom.centroid.x)\n",
    "\n",
    "    return merged_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = gpd_merge(old_fnames)\n",
    "jaywalk_df = gpd_merge(jaywalk_fnames)\n",
    "ice_df = gpd_merge(ice_fnames)\n",
    "truck_df = gpd_merge(truck_fnames)\n",
    "walker_df = gpd_merge(walker_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f'/workspace/daegu/data/external_open'\n",
    "\n",
    "old_df.to_csv(os.path.join(PATH, \"보행노인사고.csv\"), encoding='cp949', index=False)\n",
    "jaywalk_df.to_csv(os.path.join(PATH, \"무단횡단사고.csv\"), encoding='cp949', index=False)\n",
    "ice_df.to_csv(os.path.join(PATH, \"결빙사고.csv\"), encoding='cp949', index=False)\n",
    "truck_df.to_csv(os.path.join(PATH, \"화물차사고.csv\"), encoding='cp949', index=False)\n",
    "walker_df.to_csv(os.path.join(PATH, \"보행자사고.csv\"), encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_list = [old_df, jaywalk_df, ice_df, truck_df, walker_df]\n",
    "# 열이름이 동일하다 (다발지역내 사고 / 사상자 / 사망자 / 중상자 / 경상자 / 부상자 / 경상자 / 부상신고자수 합계 및 평균을 의미), TAAS API의 설명 참조\n",
    "# occrrnc_cnt : 사고건수 / caslt_cnt : 사상자수 / dth_dnv_cnt : 사망자수 / se_dnv_cnt : 중상자수 / sl_dnv_cnt : 경상자수 / wnd_dnv_cnt : 부상신고자수\n",
    "#  \n",
    "\n",
    "for gdf in gdf_list:\n",
    "    print(len(gdf), gdf.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 구 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN, TEST 데이터 전처리 함수 \n",
    "def convert_df(df):\n",
    "# 1. 사고일시, 요일 열 전처리 하는 함수 \n",
    "\n",
    "    # 사고일시를 datetime 형태로 변환\n",
    "    df['사고일시'] = pd.to_datetime(df['사고일시'])\n",
    "    \n",
    "    # 사고일시로부터 연/월/일/시 열 생성\n",
    "    df['year'] = df['사고일시'].dt.year\n",
    "    df['month'] = df['사고일시'].dt.month\n",
    "    df['day'] = df['사고일시'].dt.day\n",
    "    df['hour'] = df['사고일시'].dt.hour\n",
    "\n",
    "    # '사고일시' 로부터 요일 category형으로 label encoding \n",
    "    df['요일'] = df['사고일시'].dt.day_of_week.astype('category')\n",
    "    # 요일에서 '월'만 남기기\n",
    "    # df['요일'] = df['요일'].str.replace('요일','')   \n",
    "\n",
    "# 2. 시군구 -> 시/군/구 구분\n",
    "    df['시'] = df['시군구'].str.split(' ').str.get(0)\n",
    "    df['군'] = df['시군구'].str.split(' ').str.get(1)\n",
    "    df['구'] = df['시군구'].str.split(' ').str.get(2)\n",
    "\n",
    "# 3. 도로형태 -> 도로형태_대 / 도로형태_중 으로 구분\n",
    "    df['도로형태_대'] = df['도로형태'].str.split(' - ').str.get(0)\n",
    "    df['도로형태_중'] = df['도로형태'].str.split(' - ').str.get(1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/workspace/daegu/data'\n",
    "\n",
    "train_df = pd.read_csv(f'{PATH}/train.csv')\n",
    "test_df = pd.read_csv(f'{PATH}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = convert_df(train_df)\n",
    "test_df = convert_df(test_df)\n",
    "\n",
    "gu_list = train_df['구'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_EXT = '/workspace/daegu/data/external_open'\n",
    "\n",
    "seculight_df = pd.read_csv(f\"{PATH_EXT}/대구 보안등 정보.csv\", encoding= 'cp949')\n",
    "child_df = pd.read_csv(f\"{PATH_EXT}/대구 어린이 보호 구역 정보.csv\", encoding= 'cp949')\n",
    "parking_df = pd.read_csv(f\"{PATH_EXT}/대구 주차장 정보.csv\", encoding= 'cp949')\n",
    "cctv_df = pd.read_csv(f\"{PATH_EXT}/대구 CCTV 정보.csv\", encoding= 'cp949')\n",
    "\n",
    "df_dict = {'보안등':seculight_df, '어린이보호구역':child_df, '주차장':parking_df, 'cctv':cctv_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df와 unique list(A:구)를 입력해서 '구' 값을 추출해서 열을 새로 만드는 전처리 함수\n",
    "def preprocess_df(df, A):\n",
    "    # 1) Create a new column '구' to store the values\n",
    "    df['구'] = np.nan\n",
    "\n",
    "    # 2) Iterate through each row in the data frame\n",
    "    for index, row in df.iterrows():\n",
    "        # Check if the value in '소재지지번주소' is not NaN\n",
    "        if not pd.isna(row['소재지지번주소']):\n",
    "            # Check if any value in A is present in the '소재지지번주소' column\n",
    "            for value in A:\n",
    "                if value in row['소재지지번주소']:\n",
    "                    # If found, store the value in column '구'\n",
    "                    df.at[index, '구'] = value\n",
    "                    break  # Break the loop if a match is found     \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in df_dict.items():\n",
    "    print(key, '|열 개수:',  len(df.columns), '|열 이름:', df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in df_dict.items():\n",
    "     df = preprocess_df(df, gu_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in df_dict.items():\n",
    "    print(key, '|열 개수:',  len(df.columns), '|열 이름:', df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seculight_df.to_csv(f\"{PATH_EXT}/대구 보안등 정보_구추가.csv\", encoding= 'cp949', index=False)\n",
    "child_df.to_csv(f\"{PATH_EXT}/대구 어린이 보호 구역 정보_구추가.csv\", encoding= 'cp949', index=False)\n",
    "parking_df.to_csv(f\"{PATH_EXT}/대구 주차장 정보_구추가.csv\", encoding= 'cp949', index=False)\n",
    "cctv_df.to_csv(f\"{PATH_EXT}/대구 CCTV 정보_구추가.csv\", encoding= 'cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_df = pd.concat(df_dict.values(), axis=0)[['위도', '경도', '구']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_df = gu_df.dropna()\n",
    "\n",
    "X = gu_df[['위도', '경도']]\n",
    "y = gu_df['구']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 909\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supervised.automl import AutoML\n",
    "\n",
    "model = AutoML(\n",
    "    mode = 'Compete',\n",
    "    ml_task = 'multiclass_classification',\n",
    "    algorithms = ['LightGBM', 'CatBoost', 'Xgboost'],\n",
    "    n_jobs = -1,\n",
    "    random_state = SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\ttrain's multi_logloss: 29.2247\tvalidation's multi_logloss: 29.1973\n",
      "[44]\ttrain's multi_logloss: 29.0253\tvalidation's multi_logloss: 29.0003\n",
      "[45]\ttrain's multi_logloss: 30.1667\tvalidation's multi_logloss: 30.364\n",
      "[46]\ttrain's multi_logloss: 30.0096\tvalidation's multi_logloss: 30.2011\n",
      "[47]\ttrain's multi_logloss: 29.9975\tvalidation's multi_logloss: 30.2011\n",
      "[48]\ttrain's multi_logloss: 30.0265\tvalidation's multi_logloss: 30.1934\n",
      "[49]\ttrain's multi_logloss: 29.9047\tvalidation's multi_logloss: 30.1002\n",
      "[50]\ttrain's multi_logloss: 29.9018\tvalidation's multi_logloss: 30.0924\n",
      "[51]\ttrain's multi_logloss: 29.751\tvalidation's multi_logloss: 29.9462\n",
      "2_Default_LightGBM logloss 1.333145 trained in 35.7 seconds\n",
      "3_Default_Xgboost logloss 0.103263 trained in 54.54 seconds\n",
      "4_Default_CatBoost logloss 0.135755 trained in 387.75 seconds\n",
      "* Step not_so_random will try to check up to 27 models\n",
      "[1]\ttrain's multi_logloss: 0.956523\tvalidation's multi_logloss: 1.12109\n",
      "[2]\ttrain's multi_logloss: 7.74298\tvalidation's multi_logloss: 7.5945\n",
      "[3]\ttrain's multi_logloss: 9.63704\tvalidation's multi_logloss: 9.53801\n",
      "[4]\ttrain's multi_logloss: 11.5703\tvalidation's multi_logloss: 11.7471\n",
      "[5]\ttrain's multi_logloss: 11.6453\tvalidation's multi_logloss: 11.6197\n",
      "[6]\ttrain's multi_logloss: 12.8297\tvalidation's multi_logloss: 12.9276\n",
      "[7]\ttrain's multi_logloss: 14.1588\tvalidation's multi_logloss: 14.2467\n",
      "[8]\ttrain's multi_logloss: 14.7872\tvalidation's multi_logloss: 15.0227\n",
      "[9]\ttrain's multi_logloss: 15.6651\tvalidation's multi_logloss: 15.6925\n",
      "[10]\ttrain's multi_logloss: 16.3031\tvalidation's multi_logloss: 16.2845\n",
      "[11]\ttrain's multi_logloss: 17.0266\tvalidation's multi_logloss: 17.0345\n",
      "[12]\ttrain's multi_logloss: 17.6294\tvalidation's multi_logloss: 17.9018\n",
      "[13]\ttrain's multi_logloss: 18.879\tvalidation's multi_logloss: 19.4181\n",
      "[14]\ttrain's multi_logloss: 19.858\tvalidation's multi_logloss: 20.1743\n",
      "[15]\ttrain's multi_logloss: 18.9994\tvalidation's multi_logloss: 19.2712\n",
      "[16]\ttrain's multi_logloss: 20.9909\tvalidation's multi_logloss: 21.0842\n",
      "[17]\ttrain's multi_logloss: 21.288\tvalidation's multi_logloss: 21.2344\n",
      "[18]\ttrain's multi_logloss: 22.8217\tvalidation's multi_logloss: 22.9967\n",
      "[19]\ttrain's multi_logloss: 23.5156\tvalidation's multi_logloss: 23.4715\n",
      "[20]\ttrain's multi_logloss: 23.5989\tvalidation's multi_logloss: 23.509\n",
      "[21]\ttrain's multi_logloss: 26.1626\tvalidation's multi_logloss: 26.0946\n",
      "[22]\ttrain's multi_logloss: 26.8688\tvalidation's multi_logloss: 26.8471\n",
      "[23]\ttrain's multi_logloss: 26.1187\tvalidation's multi_logloss: 26.3478\n",
      "[24]\ttrain's multi_logloss: 30.2576\tvalidation's multi_logloss: 30.3795\n",
      "[25]\ttrain's multi_logloss: 29.6451\tvalidation's multi_logloss: 29.5894\n",
      "[26]\ttrain's multi_logloss: 29.8329\tvalidation's multi_logloss: 29.8754\n",
      "[27]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[28]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[29]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[30]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[31]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[32]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[33]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[34]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[35]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[36]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[37]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[38]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[39]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[40]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[41]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[42]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[43]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[44]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[45]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[46]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[47]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[48]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[49]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[50]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "[51]\ttrain's multi_logloss: 29.6914\tvalidation's multi_logloss: 29.7355\n",
      "14_LightGBM logloss 0.853743 trained in 29.34 seconds\n",
      "5_Xgboost logloss 0.166352 trained in 302.23 seconds\n",
      "23_CatBoost logloss 0.18188 trained in 376.53 seconds\n",
      "[1]\ttrain's multi_logloss: 1.39469\tvalidation's multi_logloss: 1.42539\n",
      "[2]\ttrain's multi_logloss: 15.0693\tvalidation's multi_logloss: 15.0363\n",
      "[3]\ttrain's multi_logloss: 15.2706\tvalidation's multi_logloss: 15.6609\n",
      "[4]\ttrain's multi_logloss: 18.6309\tvalidation's multi_logloss: 18.6052\n",
      "[5]\ttrain's multi_logloss: 21.3639\tvalidation's multi_logloss: 21.4775\n",
      "[6]\ttrain's multi_logloss: 21.0614\tvalidation's multi_logloss: 21.1831\n",
      "[7]\ttrain's multi_logloss: 23.3349\tvalidation's multi_logloss: 23.646\n",
      "[8]\ttrain's multi_logloss: 24.9087\tvalidation's multi_logloss: 25.069\n",
      "[9]\ttrain's multi_logloss: 27.6941\tvalidation's multi_logloss: 27.6197\n",
      "[10]\ttrain's multi_logloss: 26.4453\tvalidation's multi_logloss: 26.2994\n",
      "[11]\ttrain's multi_logloss: 27.6617\tvalidation's multi_logloss: 27.612\n",
      "[12]\ttrain's multi_logloss: 28.6297\tvalidation's multi_logloss: 28.6308\n",
      "[13]\ttrain's multi_logloss: 31.4865\tvalidation's multi_logloss: 31.365\n",
      "[14]\ttrain's multi_logloss: 31.5002\tvalidation's multi_logloss: 31.365\n",
      "[15]\ttrain's multi_logloss: 31.5062\tvalidation's multi_logloss: 31.365\n",
      "[16]\ttrain's multi_logloss: 31.514\tvalidation's multi_logloss: 31.3728\n",
      "[17]\ttrain's multi_logloss: 31.5209\tvalidation's multi_logloss: 31.3805\n",
      "[18]\ttrain's multi_logloss: 31.5209\tvalidation's multi_logloss: 31.3805\n",
      "[19]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[20]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[21]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[22]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[23]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[24]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[25]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[26]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[27]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[28]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[29]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[30]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[31]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[32]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[33]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[34]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[35]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[36]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[37]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[38]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[39]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[40]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[41]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[42]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[43]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[44]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[45]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[46]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[47]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[48]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[49]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[50]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "[51]\ttrain's multi_logloss: 31.5303\tvalidation's multi_logloss: 31.3805\n",
      "15_LightGBM logloss 0.832532 trained in 38.4 seconds\n",
      "6_Xgboost logloss 0.129266 trained in 126.69 seconds\n",
      "24_CatBoost logloss 0.13462 trained in 415.72 seconds\n",
      "[1]\ttrain's multi_logloss: 0.769285\tvalidation's multi_logloss: 1.02122\n",
      "[2]\ttrain's multi_logloss: 7.60306\tvalidation's multi_logloss: 7.77008\n",
      "[3]\ttrain's multi_logloss: 9.95727\tvalidation's multi_logloss: 9.91772\n",
      "[4]\ttrain's multi_logloss: 11.2168\tvalidation's multi_logloss: 11.2835\n",
      "[5]\ttrain's multi_logloss: 11.5131\tvalidation's multi_logloss: 11.6153\n",
      "[6]\ttrain's multi_logloss: 12.51\tvalidation's multi_logloss: 12.7159\n",
      "[7]\ttrain's multi_logloss: 13.5089\tvalidation's multi_logloss: 13.6385\n",
      "[8]\ttrain's multi_logloss: 14.0441\tvalidation's multi_logloss: 14.1261\n",
      "[9]\ttrain's multi_logloss: 16.1404\tvalidation's multi_logloss: 16.3535\n",
      "[10]\ttrain's multi_logloss: 16.1631\tvalidation's multi_logloss: 16.0804\n",
      "[11]\ttrain's multi_logloss: 16.1525\tvalidation's multi_logloss: 16.4505\n",
      "[12]\ttrain's multi_logloss: 17.6719\tvalidation's multi_logloss: 17.8672\n",
      "[13]\ttrain's multi_logloss: 19.0188\tvalidation's multi_logloss: 19.3792\n",
      "[14]\ttrain's multi_logloss: 20.1072\tvalidation's multi_logloss: 20.493\n",
      "[15]\ttrain's multi_logloss: 21.5764\tvalidation's multi_logloss: 21.5653\n",
      "[16]\ttrain's multi_logloss: 21.6754\tvalidation's multi_logloss: 21.7365\n",
      "[17]\ttrain's multi_logloss: 22.8977\tvalidation's multi_logloss: 23.0855\n",
      "[18]\ttrain's multi_logloss: 23.7354\tvalidation's multi_logloss: 23.9164\n",
      "[19]\ttrain's multi_logloss: 24.8217\tvalidation's multi_logloss: 25.1585\n",
      "[20]\ttrain's multi_logloss: 25.117\tvalidation's multi_logloss: 25.3069\n",
      "[21]\ttrain's multi_logloss: 27.12\tvalidation's multi_logloss: 27.2538\n",
      "[22]\ttrain's multi_logloss: 27.7952\tvalidation's multi_logloss: 28.0924\n",
      "[23]\ttrain's multi_logloss: 27.8647\tvalidation's multi_logloss: 28.176\n",
      "[24]\ttrain's multi_logloss: 29.0394\tvalidation's multi_logloss: 29.2389\n",
      "[25]\ttrain's multi_logloss: 31.9533\tvalidation's multi_logloss: 31.9936\n",
      "[26]\ttrain's multi_logloss: 31.5153\tvalidation's multi_logloss: 31.6211\n",
      "[27]\ttrain's multi_logloss: 31.6607\tvalidation's multi_logloss: 31.7996\n",
      "[28]\ttrain's multi_logloss: 31.6538\tvalidation's multi_logloss: 31.7841\n",
      "[29]\ttrain's multi_logloss: 31.6503\tvalidation's multi_logloss: 31.7841\n",
      "[30]\ttrain's multi_logloss: 31.6314\tvalidation's multi_logloss: 31.722\n",
      "[31]\ttrain's multi_logloss: 31.7064\tvalidation's multi_logloss: 31.8151\n",
      "[32]\ttrain's multi_logloss: 31.6986\tvalidation's multi_logloss: 31.8073\n",
      "[33]\ttrain's multi_logloss: 31.7202\tvalidation's multi_logloss: 31.8229\n",
      "[34]\ttrain's multi_logloss: 31.6159\tvalidation's multi_logloss: 31.7763\n",
      "[35]\ttrain's multi_logloss: 31.6478\tvalidation's multi_logloss: 31.7841\n",
      "[36]\ttrain's multi_logloss: 31.6495\tvalidation's multi_logloss: 31.7375\n",
      "[37]\ttrain's multi_logloss: 31.6607\tvalidation's multi_logloss: 31.7996\n",
      "[38]\ttrain's multi_logloss: 31.6616\tvalidation's multi_logloss: 31.7996\n",
      "[39]\ttrain's multi_logloss: 31.6616\tvalidation's multi_logloss: 31.7996\n",
      "[40]\ttrain's multi_logloss: 31.6639\tvalidation's multi_logloss: 31.8045\n",
      "[41]\ttrain's multi_logloss: 31.5857\tvalidation's multi_logloss: 31.6909\n",
      "[42]\ttrain's multi_logloss: 31.5207\tvalidation's multi_logloss: 31.6622\n",
      "[43]\ttrain's multi_logloss: 31.518\tvalidation's multi_logloss: 31.6521\n",
      "[44]\ttrain's multi_logloss: 31.518\tvalidation's multi_logloss: 31.6521\n",
      "[45]\ttrain's multi_logloss: 31.5164\tvalidation's multi_logloss: 31.6501\n",
      "[46]\ttrain's multi_logloss: 31.5119\tvalidation's multi_logloss: 31.6444\n",
      "[47]\ttrain's multi_logloss: 31.5042\tvalidation's multi_logloss: 31.6444\n",
      "[48]\ttrain's multi_logloss: 31.5005\tvalidation's multi_logloss: 31.6424\n",
      "[49]\ttrain's multi_logloss: 31.4907\tvalidation's multi_logloss: 31.6211\n",
      "[50]\ttrain's multi_logloss: 31.4887\tvalidation's multi_logloss: 31.6211\n",
      "[51]\ttrain's multi_logloss: 31.4887\tvalidation's multi_logloss: 31.6211\n",
      "16_LightGBM logloss 0.766197 trained in 51.35 seconds\n",
      "7_Xgboost logloss 0.652011 trained in 120.97 seconds\n",
      "* Step golden_features will try to check up to 3 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None 10\n",
      "Add Golden Feature: 경도_sum_위도\n",
      "Add Golden Feature: 경도_multiply_위도\n",
      "Add Golden Feature: 경도_ratio_위도\n",
      "Add Golden Feature: 위도_ratio_경도\n",
      "Add Golden Feature: 위도_diff_경도\n",
      "Created 5 Golden Features in 6.61 seconds.\n",
      "3_Default_Xgboost_GoldenFeatures logloss 0.074247 trained in 94.09 seconds\n",
      "6_Xgboost_GoldenFeatures logloss 0.068545 trained in 94.41 seconds\n",
      "* Step kmeans_features will try to check up to 3 models\n",
      "3_Default_Xgboost_KMeansFeatures logloss 0.084171 trained in 89.64 seconds\n",
      "* Step insert_random_feature will try to check up to 1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2922: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_Xgboost_GoldenFeatures_RandomFeature logloss 0.080326 trained in 107.67 seconds\n",
      "Drop features ['random_feature']\n",
      "Skip features_selection because no parameters were generated.\n",
      "* Step hill_climbing_1 will try to check up to 16 models\n",
      "25_Xgboost_GoldenFeatures logloss 0.067554 trained in 252.65 seconds\n",
      "26_Xgboost_GoldenFeatures logloss 0.06924 trained in 256.58 seconds\n",
      "* Step hill_climbing_2 will try to check up to 17 models\n",
      "27_Xgboost_GoldenFeatures logloss 0.065223 trained in 343.04 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble logloss 0.05889 trained in 19.81 seconds\n",
      "AutoML fit time: 3754.48 seconds\n",
      "AutoML best model: Ensemble\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoML(algorithms=[&#x27;LightGBM&#x27;, &#x27;CatBoost&#x27;, &#x27;Xgboost&#x27;],\n",
       "       ml_task=&#x27;multiclass_classification&#x27;, mode=&#x27;Compete&#x27;, random_state=909)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoML</label><div class=\"sk-toggleable__content\"><pre>AutoML(algorithms=[&#x27;LightGBM&#x27;, &#x27;CatBoost&#x27;, &#x27;Xgboost&#x27;],\n",
       "       ml_task=&#x27;multiclass_classification&#x27;, mode=&#x27;Compete&#x27;, random_state=909)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AutoML(algorithms=['LightGBM', 'CatBoost', 'Xgboost'],\n",
       "       ml_task='multiclass_classification', mode='Compete', random_state=909)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 및 불러오기 \n",
    "from joblib import dump, load\n",
    "\n",
    "model_filename = 'gu_model_LCX.joblib'\n",
    "dump(model, model_filename)\n",
    "\n",
    "gu_model = load(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gu model로 gpd에서 '구'를 예측하자 \n",
    "for gdf in gdf_list:\n",
    "    gdf['구'] = gu_model.predict(gdf[['위도', '경도']])\n",
    "\n",
    "    # 사용안할 열을 drop\n",
    "    cols_remove = ['geometry', 'occrrnc_cnt_mean', 'caslt_cnt_mean', 'dth_dnv_cnt_mean', 'se_dnv_cnt_mean', 'sl_dnv_cnt_mean', 'wnd_dnv_cnt_mean', '위도', '경도', 'id']\n",
    "\n",
    "    if all(column in gdf.columns for column in cols_remove):\n",
    "        gdf.drop(cols_remove, axis=1, inplace=True)\n",
    "    # gdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 df로부터 구 기준으로 집계된 새로운 df들을 만들자 (agg_dfs에 저장)\n",
    "def create_agg_df(dataframes):\n",
    "\n",
    "    aggregated_dfs = []\n",
    "\n",
    "    for df in dataframes:\n",
    "        # Perform groupby operation and aggregate based on the specified column\n",
    "        aggregated_df = df.groupby('구').sum().reset_index()\n",
    "        aggregated_dfs.append(aggregated_df)\n",
    "\n",
    "    return aggregated_dfs\n",
    "\n",
    "# Example: Create aggregated data frames based on the 'old' column\n",
    "agg_dfs = create_agg_df(gdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구</th>\n",
       "      <th>count</th>\n",
       "      <th>occrrnc_cnt_sum</th>\n",
       "      <th>caslt_cnt_sum</th>\n",
       "      <th>dth_dnv_cnt_sum</th>\n",
       "      <th>se_dnv_cnt_sum</th>\n",
       "      <th>sl_dnv_cnt_sum</th>\n",
       "      <th>wnd_dnv_cnt_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>감삼동</td>\n",
       "      <td>15.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>공평동</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>교동</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>구암동</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>남산동</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     구  count  occrrnc_cnt_sum  caslt_cnt_sum  dth_dnv_cnt_sum  \\\n",
       "0  감삼동   15.0             72.0           96.0              3.0   \n",
       "1  공평동    1.0              4.0            6.0              0.0   \n",
       "2   교동    2.0              8.0           12.0              0.0   \n",
       "3  구암동    1.0              4.0            4.0              0.0   \n",
       "4  남산동    9.0             36.0           69.0              0.0   \n",
       "\n",
       "   se_dnv_cnt_sum  sl_dnv_cnt_sum  wnd_dnv_cnt_sum  \n",
       "0            72.0            21.0              0.0  \n",
       "1             4.0             2.0              0.0  \n",
       "2             8.0             4.0              0.0  \n",
       "3             4.0             0.0              0.0  \n",
       "4            36.0            28.0              5.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_dfs[-1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터와 합쳐주기 위해서 각 집계된 리스트의 열이름을 구별해서 합쳐주자 \n",
    "string_list = ['old', 'jay', 'ice', 'truck', 'walker']\n",
    "\n",
    "# Iterate over each data frame in the list and modify column names\n",
    "for i, (agg_df, prefix) in enumerate(zip(agg_dfs, string_list)):\n",
    "    if prefix != '구':\n",
    "        # Modify column names based on the rules\n",
    "        new_column_names = [prefix + '_' + col if col != '구' else col for col in agg_df.columns]\n",
    "        agg_df.columns = new_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['구', 'old_count', 'old_occrrnc_cnt_sum', 'old_caslt_cnt_sum', 'old_dth_dnv_cnt_sum', 'old_se_dnv_cnt_sum', 'old_sl_dnv_cnt_sum', 'old_wnd_dnv_cnt_sum']\n",
      "['구', 'jay_count', 'jay_occrrnc_cnt_sum', 'jay_caslt_cnt_sum', 'jay_dth_dnv_cnt_sum', 'jay_se_dnv_cnt_sum', 'jay_sl_dnv_cnt_sum', 'jay_wnd_dnv_cnt_sum']\n",
      "['구', 'ice_count', 'ice_occrrnc_cnt_sum', 'ice_caslt_cnt_sum', 'ice_dth_dnv_cnt_sum', 'ice_se_dnv_cnt_sum', 'ice_sl_dnv_cnt_sum', 'ice_wnd_dnv_cnt_sum']\n",
      "['구', 'truck_count', 'truck_occrrnc_cnt_sum', 'truck_caslt_cnt_sum', 'truck_dth_dnv_cnt_sum', 'truck_se_dnv_cnt_sum', 'truck_sl_dnv_cnt_sum', 'truck_wnd_dnv_cnt_sum']\n",
      "['구', 'walker_count', 'walker_occrrnc_cnt_sum', 'walker_caslt_cnt_sum', 'walker_dth_dnv_cnt_sum', 'walker_se_dnv_cnt_sum', 'walker_sl_dnv_cnt_sum', 'walker_wnd_dnv_cnt_sum']\n"
     ]
    }
   ],
   "source": [
    "for df in agg_dfs:\n",
    "    print(df.columns.to_list() )\n",
    "    # print(len(df), len(df['구'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 36) ['구', 'old_count', 'old_occrrnc_cnt_sum', 'old_caslt_cnt_sum', 'old_dth_dnv_cnt_sum', 'old_se_dnv_cnt_sum', 'old_sl_dnv_cnt_sum', 'old_wnd_dnv_cnt_sum', 'jay_count', 'jay_occrrnc_cnt_sum', 'jay_caslt_cnt_sum', 'jay_dth_dnv_cnt_sum', 'jay_se_dnv_cnt_sum', 'jay_sl_dnv_cnt_sum', 'jay_wnd_dnv_cnt_sum', 'ice_count', 'ice_occrrnc_cnt_sum', 'ice_caslt_cnt_sum', 'ice_dth_dnv_cnt_sum', 'ice_se_dnv_cnt_sum', 'ice_sl_dnv_cnt_sum', 'ice_wnd_dnv_cnt_sum', 'truck_count', 'truck_occrrnc_cnt_sum', 'truck_caslt_cnt_sum', 'truck_dth_dnv_cnt_sum', 'truck_se_dnv_cnt_sum', 'truck_sl_dnv_cnt_sum', 'truck_wnd_dnv_cnt_sum', 'walker_count', 'walker_occrrnc_cnt_sum', 'walker_caslt_cnt_sum', 'walker_dth_dnv_cnt_sum', 'walker_se_dnv_cnt_sum', 'walker_sl_dnv_cnt_sum', 'walker_wnd_dnv_cnt_sum']\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "agg_merged_df = reduce(lambda left, right: pd.merge(left, right, on='구', how='outer'), agg_dfs)\n",
    "agg_merged_df = agg_merged_df.fillna(0)\n",
    "print(agg_merged_df.shape, agg_merged_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39609, 67) (10963, 52)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.merge(train_df, agg_merged_df, on='구', how='left').fillna(0)\n",
    "test_df = pd.merge(test_df, agg_merged_df, on='구', how='left').fillna(0)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구</th>\n",
       "      <th>보안등_수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가창면</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>각산동</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>갈산동</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>감삼동</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>검단동</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     구  보안등_수\n",
       "0  가창면   1123\n",
       "1  각산동    139\n",
       "2  갈산동    351\n",
       "3  감삼동    941\n",
       "4  검단동    391"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_sec_df = seculight_df[['구', '설치개수']].groupby(['구']).sum().reset_index()\n",
    "agg_sec_df.columns = ['구', '보안등_수']\n",
    "agg_sec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구</th>\n",
       "      <th>어린이_CCTV_설치대수</th>\n",
       "      <th>어린이구역_수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가창면</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>검단동</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>고성동1가</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>고성동2가</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>관음동</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       구  어린이_CCTV_설치대수  어린이구역_수\n",
       "0    가창면            0.0        8\n",
       "1    검단동            4.0        1\n",
       "2  고성동1가            2.0        1\n",
       "3  고성동2가            2.0        1\n",
       "4    관음동           22.0        5"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_df['count'] = 1\n",
    "agg_child_df = child_df[['구', 'CCTV설치대수', 'count']].groupby('구').sum().reset_index()\n",
    "agg_child_df.columns = ['구', '어린이_CCTV_설치대수', '어린이구역_수']\n",
    "agg_child_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구</th>\n",
       "      <th>주차장_수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가창면</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>갈산동</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>감삼동</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>검단동</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>계산동1가</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       구  주차장_수\n",
       "0    가창면      2\n",
       "1    갈산동      4\n",
       "2    감삼동      4\n",
       "3    검단동      1\n",
       "4  계산동1가      2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df['count'] = 1\n",
    "agg_parking_df = parking_df[['구', 'count']].groupby('구').sum().reset_index()\n",
    "agg_parking_df.columns = ['구', '주차장_수']\n",
    "agg_parking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 5) 182 ['구', '보안등_수', '어린이_CCTV_설치대수', '어린이구역_수', '주차장_수']\n"
     ]
    }
   ],
   "source": [
    "agg_csv_dfs = [agg_sec_df, agg_child_df, agg_parking_df]\n",
    "\n",
    "agg_csv_df = reduce(lambda left, right: pd.merge(left, right, on='구', how='outer'), agg_csv_dfs)\n",
    "agg_csv_df = agg_csv_df.fillna(0)\n",
    "print(agg_csv_df.shape, len(agg_csv_df['구'].unique()), agg_csv_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39609, 71) (10963, 56)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.merge(train_df, agg_csv_df, on='구', how='left').fillna(0)\n",
    "test_df = pd.merge(test_df, agg_csv_df, on='구', how='left').fillna(0)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(f\"train_new.csv\", encoding= 'cp949', index=False)\n",
    "test_df.to_csv(f\"test_new.csv\", encoding= 'cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
